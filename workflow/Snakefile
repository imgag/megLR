#=============================================================================#
#               O N T     A N A L Y S I S     T O O L S                       #
#=============================================================================#

#_____ CONFIGURATION __________________________________________________________#

import csv
import os
import pathlib
import re
from glob import glob
from collections import defaultdict
# Needed by DGE:
import pandas as pd
from collections import OrderedDict
from scripts.bytes_to_human import human2bytes, bytes2human

include: "rules/helper_scripts.smk"

configfile: workflow.source_path('../config/config_defaults.yml')
load_project_config(config['project_config'])
print_message()

#_____ PARSE SAMPLE FILE _______________________________________________________#

ID_samples = set()
ID_folders = set()
ID_runs = set()
ID_barcode_folders = set()
map_samples_folder = defaultdict(list)
map_samples_barcode = defaultdict(list)
map_runs_folder = defaultdict(list)

# Parse sample and run id connection table
if  os.path.isfile(config['sample_file']):
    with open(config['sample_file']) as f:
        reader=csv.reader(f, delimiter="\t")
        for row in reader:
            if len(row) == 0:
                pass
            elif len(row) == 2:
                ID_samples.add(row[0])
                ID_folders.add(row[1])
                map_samples_folder[row[0]].append(row[1])
            # Add barcodes to folder (tuple)
            elif len(row) == 3:
                ID_samples.add(row[0])
                ID_folders.add(row[1])
                ID_barcode_folders.add(row[1])
                map_samples_barcode[row[0]].append((row[1], row[2]))
            else :
                print("Wrong number of columns in row: ", row, len(row))
                pass

# If no FOFN available, check dir for  Folders with "Sample_" Prefix
else:
    ID_samples, = glob_wildcards('Sample_{sample}/')
    ID_samples = [sample for sample in ID_samples if '/' not in sample]
    print("Automatically detected the following samples in project dir: ")
    print(ID_samples)
    if not ID_samples: 
        print("NO samples ... quitting")
        exit(1)

# Create run names from the Folder_IDs. IE only `20211213_1214_2-A7-D7_PAI80186_4d463244_02064` 
# Regex for run name:   "^\d{8}_\d{4}_\w+-\w+-\w+_\D{3}\d{5}_\w{8}_\w{5}$"
# New folder names: "QIGMI017AF_21061LRa001_02013" or "21061LRa001_02013"
# Regex for new run name:   "^(?:Q\w{9}_)?\d{5}\w*_\d{5}$"

for folder in ID_folders:
    run =  os.path.basename(folder)
    if config['skip_name_check']:
        ID_runs.add(run)
        map_runs_folder[run].append(folder)
    else:
        run_pattern = re.compile("^(?:Q\w{9}_)?\d{5}\w*_\d{5}$")
        if bool(run_pattern.match(run)):
            ID_runs.add(run)
            map_runs_folder[run].append(folder)
        else:
            print("Run name has incorrect name: ", run)
            print("Forgot adding run suffix? Override by config setting `skip_name_check`")
            exit(1)

if config['verbose']:
    print("Samples: ", ID_samples)
    print("Folders:", ID_folders)
    print("Runs:", ID_runs)
    print("Barcode Folders: ", ID_barcode_folders)
    print("Map Folder:", map_samples_folder)
    print("Map Barcode:", map_samples_barcode)
    print("Map Runs:", map_runs_folder)

#_____ INCLUDE MODULES ________________________________________________________#

include: "rules/fetch_reads.smk"
include: "rules/basecalling.smk"
include: "rules/mapping.smk"
include: "rules/assembly.smk"
include: "rules/variant_calling.smk"
include: "rules/structural_variant_calling.smk"
include: "rules/cdna.smk"
include: "rules/transcriptome.smk"
include: "rules/expression.smk"
include: "rules/dual_barcode.smk"
include: "rules/cnv.smk"
include: "rules/local_assembly.smk"
include: "rules/repeat_expansion.smk"
include: "rules/paraphase.smk"
include: "rules/qc.smk"
include: "rules/qc_database.smk"

localrules:
    copy_barcode_stats,
    copy_mux_stats,
    copy_run_report,
    copy_runqc,
    create_mux_plots,
    create_plots,
    fast5_to_pod5,

#_____ REQUIRED OUTPUT FILES _________________________________________________#

out = {
    "modbases": expand("Sample_{s}/{s}.mod.bam", s=ID_samples),
    "modification": expand("Sample_{s}/{s}.mod.unmapped.bam", s=ID_samples),
    "duplex": expand("Sample_{s}/{s}.duplex.unmapped.bam", s=ID_samples),
    "fastq": expand("Sample_{s}/{s}.fastq.gz", s=ID_samples),
    "mapping": [_primary_alignment_path(s) for s in ID_samples],
    "assembly": expand(
        "Sample_{s}/{s}.asm.{asm}.fasta",
        s=ID_samples,
        asm=config["assembly"]["methods"],
    ),
    "variant_calling": [],  # Added later
    "structural_variant_calling": [],  # Added later
    "cdna": expand(
        "Sample_{s}/{s}.spliced{d}.bam",
        s=ID_samples,
        d=".dedup" if config["cdna"]["deduplicate"] else "",
    ),
    "transcriptome": [],  # Added later
    "expression": expand("Sample_{s}/{s}.counts.tsv", s=ID_samples),
    "differential_transcript_usage": ["de_analysis/dtu_plots.pdf"],
    "dual_demux": expand("Sample_{s}/{s}_barcode_distribution.pdf", s=ID_samples)
    + expand("Sample_{s}/coverage_stats.txt", s=ID_samples),
    "cnv": [
        expand("cnvkit/{s}/{s}.all.png", s=ID_samples),
        expand(
            "cnvkit/{s}/{s}.{r}.png",
            s=ID_samples,
            r=config["cnvkit"]["scatter"]["region"],
        ),
        expand("cnvkit/{s}/{s}.call.txt", s=ID_samples),
        expand("cnvkit/{s}/{s}.sex.txt", s=ID_samples),
    ],
    "local_assembly": expand(
        "local_assembly/Sample_{s}/{t}{hp}.asm.fasta",
        s=ID_samples,
        t=config["local_assembly"]["regions"],
        hp=[".hp" + x if x else "" for x in config["local_assembly"]["haplotypes"]],
    )
    + expand(
        "local_assembly/Sample_{s}/{t}{hp}.aln_ref.bam",
        s=ID_samples,
        t=config["local_assembly"]["regions"],
        hp=[".hp" + x if x else "" for x in config["local_assembly"]["haplotypes"]],
    )
    + expand(
        "local_assembly/Sample_{s}/{t}{hp}.aln_region.sam",
        s=ID_samples,
        t=config["local_assembly"]["regions"],
        hp=[".hp" + x if x else "" for x in config["local_assembly"]["haplotypes"]],
    ),
    "repeat_expansion": [],
    "paraphase": [
        expand("Sample_{s}/paraphase_meglr/{s}.paraphase.bam",
        s=ID_samples),
        expand("Sample_{s}/paraphase_meglr/annotation.done",
        s=ID_samples)
    ],
    "qc": ["qc/multiqc_report.html"],
    "qc_db": [
        expand(config["run_db_root"] + "/runs/{run}/{run}.pycoQC.html", run=ID_runs),
        expand(config["run_db_root"] + "/runs/{run}/{run}.pycoQC.json", run=ID_runs),
        expand(config["run_db_root"] + "/runs/{run}/{run}.report.md", run=ID_runs),
        expand(config["run_db_root"] + "/runs/{run}/{run}.barcodes.tsv", run=ID_runs),
        expand(config["run_db_root"] + "/runs/{run}/{run}.mux.csv", run=ID_runs),
        expand(config["run_db_root"] + "/runs/{run}/{run}.pore_yield.png", run=ID_runs),
        expand(
            config["run_db_root"] + "/runs/{run}/{run}.pore_status.png", run=ID_runs
        ),
        config["run_db_root"] + "/ont_runs_multiqc.html",
        config["run_db_root"] + "/ont_runs.xlsx",
        config["run_db_root"] + "/plot/timeline.png",
        config["run_db_root"] + "/ont_runs_multiqc.html",
    ],
}

# Add Variant calling outputs:
if config['vc']['pepper']:
    out['variant_calling'] += expand("Sample_{s}/{s}.pepper_margin_dv.vcf.gz", s=ID_samples)
if config['vc']['clair3']:
    out['variant_calling'] += expand("Sample_{s}/{s}.clair3.vcf.gz", s=ID_samples)
if config['vc']['deepvariant']:
    out['variant_calling'] += expand("Sample_{s}/{s}.dv.vcf.gz", s=ID_samples)

# Output phased VCF if required:
if config['vc']['phased_output']: 
    if config['vc']['clair3']:
        out['variant_calling'] += expand("Sample_{s}/{s}.phased.clair3.vcf.gz", s=ID_samples)
    if config['vc']['deepvariant']:
        out['variant_calling'] += expand("Sample_{s}/{s}.phased.dv.vcf.gz", s=ID_samples)

ruleorder: longphase_haplotag > pepper_haplotagged_bam
# Create haplotagged bam if required
if config['vc']['haplotagged_bam']:
    out['variant_calling'] += expand("Sample_{s}/{s}.haplotagged.bam", s=ID_samples)
    if config['phasing']['haplotagging_input'] == "pepper":
        ruleorder: pepper_haplotagged_bam > longphase_haplotag        

# Add SV calling outputs:
if config['sv']['sniffles']:
    out['structural_variant_calling'] += expand("Sample_{s}/{s}.sv_sniffles.vcf.gz", s=ID_samples),
if config['sv']['cutesv']:
    out['structural_variant_calling'] +=expand("Sample_{s}/{s}.sv_cutesv.vcf.gz", s=ID_samples),
if config['sv']['dipdiff']:
    out['structural_variant_calling'] +=expand("Sample_{s}/{s}.sv_dipdiff.vcf.gz", s=ID_samples)

# Add Repeat expansion outputs:
if 'nanorepeat' in config['repeat_expansion']['methods']:
    out['repeat_expansion'] += expand("Sample_{s}/repeat_expansions/nanorepeat", s = ID_samples),
if 'straglr' in config['repeat_expansion']['methods']:
    out['repeat_expansion'] += expand("Sample_{s}/repeat_expansions/straglr.bed", s = ID_samples)


# Add transcriptome analysis outputs:
if 'stringtie' in config['transcriptome']['methods']:
    out['transcriptome'] += expand("Sample_{s}/{s}.stringtie.gtf", s=ID_samples)
    out['transcriptome'] += expand("qc/sqanti/{s}_stringtie/{s}_stringtie_classification.txt", s = ID_samples),
    out['expression'] += expand("Sample_{s}/{s}.stringtie.annotated_expression.tsv", s = ID_samples),

for method in config["transcriptome"]["alignment"]:
    out['transcriptome'] += expand("Sample_{s}/{s}.transcripts.{method}.bam", s=ID_samples, method=method)
    out['expression'] += [f"isoform_counts/merged_counts_{method}.tsv"]

if 'flair' in config['transcriptome']['methods']:
    out['transcriptome'] += expand("Sample_{s}/{s}.flair.gtf", s=ID_samples),
    out['transcriptome'] += expand("qc/sqanti/{s}_flair/{s}_flair_classification.txt", s = ID_samples),
    out['expression'] += expand("Sample_{s}/flair/{s}.counts_matrix.tsv", s = ID_samples),

ruleorder: join_fastq > mod_unmapped_fastq
ruleorder: map_genome_all > map_genome_all_modification
ruleorder: dorado_basecalling_mod > join_bam

if "modification" in config["steps"]:
    # use existing mod unmapped BAM files from run folder
    if config["use_existing_modubam"]:
        ruleorder: join_bam > dorado_basecalling_mod
    # use FASTQs from dorado basecalling
    ruleorder: mod_unmapped_fastq > join_fastq
    # integrate tags from unmapped bam (methylation info)
    ruleorder: map_genome_all_modification > map_genome_all

# Include only results for selected analysis modules
out_selected = [out[step] for step in config['steps']]

if config['verbose']:
    print("Required outputs:")
    print(out_selected)


rule all:
    input:
        [y for x in out_selected for y in x]
